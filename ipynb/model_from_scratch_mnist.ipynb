{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780a5bd3",
   "metadata": {},
   "source": [
    "# Creating a Digit Classifier (Almost) from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9548ab48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krm/mambaforge/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libc10_cuda.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1973927",
   "metadata": {},
   "source": [
    "We're creating a model that can classify any images as a 3 or a 7. We'll use a sample of MNIST that contains just these.\n",
    "\n",
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7d01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78f1f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('/home/krm/.fastai/data/mnist_sample/labels.csv'),Path('/home/krm/.fastai/data/mnist_sample/train'),Path('/home/krm/.fastai/data/mnist_sample/valid')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccddb63",
   "metadata": {},
   "source": [
    "The sample data is divided into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9525ec2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#2) [Path('/home/krm/.fastai/data/mnist_sample/train/7'),Path('/home/krm/.fastai/data/mnist_sample/train/3')],\n",
       " (#2) [Path('/home/krm/.fastai/data/mnist_sample/valid/7'),Path('/home/krm/.fastai/data/mnist_sample/valid/3')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/\"train\").ls(), (path/\"valid\").ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e10436",
   "metadata": {},
   "source": [
    "Get a list of the training set of 3s and 7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0f5197",
   "metadata": {},
   "outputs": [],
   "source": [
    "threes = (path/\"train\"/\"3\").ls().sorted()\n",
    "sevens = (path/\"train\"/\"7\").ls().sorted()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac100836",
   "metadata": {},
   "source": [
    "Have a look at one of the 3s. We use the `Image` class from PIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d9c6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAklEQVR4nGNgGLyAUSh2yb////79m44hxasy/e/fv3///r31/ioXumTk379/v64JCgpimvJ3GlSMBSH9f333KQYGBlVZBjV0nYLTjRkYGBgYNJ7+/TsZu6OCz739+/cyBxYZt/7Pv//+/bvVCIscyxmIc7PgIkwISUZ5BoYHqxL/CmO1MG+9jxADw88vdtjdw8DAwHD1bw0WY6FgLUMQbp3v/p5D08m897woVISb4TCacvEbf+dD1AX8/huBbtjyv38VGRgYGOy//b0ijy4psvfv7QIGhvCLyIEABzZf/v44efLj37+XPbC4MvDn379///69iD2AhE/+/XszGiMVUB8AAIBLZ4nJiClnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img3_path = threes[2]\n",
    "img3 = Image.open(img3_path)\n",
    "img3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8c273d",
   "metadata": {},
   "source": [
    "We can 'see' the image as a collection of digits using numpy arrays of pytorch tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d85d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,  13,  36],\n",
       "       [  0,   0,   0,   0,  89, 253],\n",
       "       [  0,   0,   0,   0,  89, 253],\n",
       "       [  0,   0,   0,   0,  17, 151]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(img3)[4:10, 4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8730aae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  13,  36],\n",
       "        [  0,   0,   0,   0,  89, 253],\n",
       "        [  0,   0,   0,   0,  89, 253],\n",
       "        [  0,   0,   0,   0,  17, 151]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(img3)[4:10, 4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8282421",
   "metadata": {},
   "source": [
    "Next we create tensors for each of the 3s and 7s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c1eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_tensors = [tensor(Image.open(path)) for path in threes]\n",
    "seven_tensors = [tensor(Image.open(path)) for path in sevens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8ebff9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(three_tensors), len(seven_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b9cee3",
   "metadata": {},
   "source": [
    "Use fastai's show_image to see a seven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1ccc525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(seven_tensors[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b1cd89",
   "metadata": {},
   "source": [
    "We stack each list of tensors into a single one of 3 axes (rank 3), convert to float for some operations. We also scale to values between 0 and 1 (better for the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e54f65b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6131, 28, 28]), torch.Size([6265, 28, 28]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_threes = torch.stack(three_tensors).float() / 255\n",
    "stacked_sevens = torch.stack(seven_tensors).float() / 255\n",
    "stacked_threes.shape, stacked_sevens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b7dfac",
   "metadata": {},
   "source": [
    "We create a training input collection by concatenating the two stacked tensors into one. We use the `view` method to reshape the tensor into two dimensions. `-1` means making the first dimension as big as possible to accomodate the new shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "439bd51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28 * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36dcd0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 784])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d635368e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2efe0d",
   "metadata": {},
   "source": [
    "Each item along axis 0 is now a list of 784 floats representing a single image.\n",
    "\n",
    "We next create labels for our training input. Our objective is to classify whether an image is a 3 or not. The labels for 3s will be 1 (True) and for 7s will be 0 (False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df28c732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_flat = tensor([1] * len(threes) + [0] * len(sevens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa67743a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_flat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad92665",
   "metadata": {},
   "source": [
    "We need to have a 2D tensor with the second dimension being a size of 1. We use pytorch's `unsqueeze` for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f60d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y_flat.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d37ddca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dadefa",
   "metadata": {},
   "source": [
    "In pytorch, a dataset needs to return a tuple of (x, y) when indexed. We therefore zip training input and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "290986ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), torch.Size([1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = list(zip(train_x, train_y))\n",
    "x0, y0 = dataset[0]\n",
    "x0.shape, y0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad28448",
   "metadata": {},
   "source": [
    "We do the same preparation to the validation data as we've done for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8f59e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_threes = (path/\"valid\"/\"3\").ls().sorted()\n",
    "v_sevens = (path/\"valid\"/\"7\").ls().sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "476331ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_three_tensors = [tensor(Image.open(path)) for path in v_threes]\n",
    "v_seven_tensors = [tensor(Image.open(path)) for path in v_sevens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccded4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_v_threes = torch.stack(v_three_tensors).float()/255\n",
    "stacked_v_sevens = torch.stack(v_seven_tensors).float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e337bb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2038, 784])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x = torch.cat([stacked_v_threes, stacked_v_sevens]).view(-1, 28 * 28)\n",
    "valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d606dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2038, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_y = tensor([1] * len(v_threes) + [0] * len(v_sevens)).unsqueeze(1)\n",
    "valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0cc08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0700da",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The initial model will be a linear function with weights for each pixel and a bias. We'll need to calculate gradients for each of these, so we call `requires_grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "206a6425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size) * std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8601cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), torch.Size([1]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = init_params((28*28, 1))\n",
    "bias = init_params(1)\n",
    "weights.shape, bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d0191fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x_batch): return x_batch@weights + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7169551",
   "metadata": {},
   "source": [
    "Next, we need to define a loss function that is sensitive to small changes in the parameters. For each batch of predictions, we calculate distance from the target values, and get the mean.\n",
    "\n",
    "We also need to coerce the predictions to values between 0 and 1, so we'll use a sigmoid function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e45f8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eaf47311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    predictions = sigmoid(predictions)\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c7e1a",
   "metadata": {},
   "source": [
    "We now have enough to calculate gradients. We define a procedure that makes predictions, calculates the loss, then calculates the gradients that would minimise the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4410c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradients(x_batch, y_batch, model):\n",
    "    predictions = model(x_batch)\n",
    "    loss = mnist_loss(predictions, y_batch)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4175ee",
   "metadata": {},
   "source": [
    "We need to iteratively process mini batches until we exhaust the entire dataset. The `fastai` library provides a `DataLoader` class that will shuffle the dataset and provide batches of input and their corresponding targets according to the batch size we provide. We can iterate through this to process the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d876a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(dataset, batch_size=256)\n",
    "valid_dl = DataLoader(validation_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e67c18d",
   "metadata": {},
   "source": [
    "Now we can encode the process of training through an entire epoch. With each mini-batch, we optimize the parameters using the gradients and learning rate. We're adjusting each parameter in opposite direction of the gradient to get closer to a minimized loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b91f8d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, learning_rate, params):\n",
    "    for x, y in train_dl:\n",
    "        calculate_gradients(x, y, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad * learning_rate\n",
    "            p.grad.zero_()  # reset gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f273b5",
   "metadata": {},
   "source": [
    "We'll also calculate an accuracy metric for each epoch so that we can observe that the accuracy is improving with each successive epoch.\n",
    "\n",
    "We first calculate the metric for each batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb55ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(predictions, targets):\n",
    "    predictions = sigmoid(predictions)\n",
    "    correct = (predictions > 0.5) == targets\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71b728",
   "metadata": {},
   "source": [
    "Then average it for the entire epoch (rounded off to 4 decimal places):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cbd6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accuracies = [batch_accuracy(model(x_batch), y_batch) for x_batch, y_batch in valid_dl]\n",
    "    return round(torch.stack(accuracies).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d10699",
   "metadata": {},
   "source": [
    "We can now see the model performance for the entire epoch. We define a procedure that takes in the model, parameters, learning rate and number of epochs and prints out the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8300437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(model, params, learning_rate, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model, learning_rate, params)\n",
    "        print(validate_epoch(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "663dda8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5096\n",
      "0.6146\n",
      "0.8583\n",
      "0.9306\n",
      "0.9526\n",
      "0.9628\n",
      "0.9677\n",
      "0.9697\n",
      "0.9706\n",
      "0.9706\n",
      "0.9726\n",
      "0.9731\n",
      "0.9736\n",
      "0.9751\n",
      "0.9761\n",
      "0.9761\n",
      "0.9765\n",
      "0.9765\n",
      "0.978\n",
      "0.9785\n"
     ]
    }
   ],
   "source": [
    "learn(linear, params=(weights, bias), learning_rate=1.0, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b2dc8f",
   "metadata": {},
   "source": [
    "We see that the accuracy gradually improves to approx 96%. \n",
    "\n",
    "### Pytorch/FastAI conveniences\n",
    "\n",
    "Pytorch provides some handy functionality that we can use to simplify the process above.\n",
    "`nn.Linear` will combine what `init_params` and `linear` do together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3893fe9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([1]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = nn.Linear(28 * 28, 1)\n",
    "weights, bias = linear_model.parameters()\n",
    "weights.shape, bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd90486",
   "metadata": {},
   "source": [
    "We can also create an optimizer class that will optimize parameters using an interface that resembles pytorch's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8687208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptimizer:\n",
    "    def __init__(self, params, learning_rate):\n",
    "        self.params = list(params)\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params:\n",
    "            p.data -= p.grad.data * self.learning_rate\n",
    "    \n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params:\n",
    "            p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0211c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1.0\n",
    "optimizer = BasicOptimizer(linear_model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb937a",
   "metadata": {},
   "source": [
    "We can re-write `train_epoch` and `learn` to use the new optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "205174b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model):\n",
    "    for x, y in train_dl:\n",
    "        calculate_gradients(x, y, model)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "def learn(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b30e91",
   "metadata": {},
   "source": [
    "We should get similar results to the previous run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4999e5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932\n",
      "0.8364\n",
      "0.8408\n",
      "0.9121\n",
      "0.9336\n",
      "0.9463\n",
      "0.957\n",
      "0.9619\n",
      "0.9658\n",
      "0.9668\n",
      "0.9692\n",
      "0.9721\n",
      "0.9726\n",
      "0.9746\n",
      "0.9756\n",
      "0.9765\n",
      "0.9775\n",
      "0.978\n",
      "0.9785\n",
      "0.9785\n"
     ]
    }
   ],
   "source": [
    "learn(linear_model, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad74b100",
   "metadata": {},
   "source": [
    "FastAI provides the class `SGD` that does the same thing as `BasicOptimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9fa5cc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932\n",
      "0.4932\n",
      "0.6631\n",
      "0.8682\n",
      "0.918\n",
      "0.938\n",
      "0.9507\n",
      "0.957\n",
      "0.9643\n",
      "0.9658\n",
      "0.9682\n",
      "0.9702\n",
      "0.9721\n",
      "0.9741\n",
      "0.9751\n",
      "0.9761\n",
      "0.977\n",
      "0.9775\n",
      "0.978\n",
      "0.9785\n"
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28 * 28, 1)\n",
    "optimizer = SGD(linear_model.parameters(), learning_rate)\n",
    "learn(linear_model, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4018c21",
   "metadata": {},
   "source": [
    "Fast AI also provides a `Learner.fit` method which does the same thing as our `learn`. To use it, we combine the training and validation dataloaders using a `DataLoaders` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60914bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.636433</td>\n",
       "      <td>0.503578</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.566320</td>\n",
       "      <td>0.185767</td>\n",
       "      <td>0.846418</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.206707</td>\n",
       "      <td>0.184452</td>\n",
       "      <td>0.833660</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089561</td>\n",
       "      <td>0.108672</td>\n",
       "      <td>0.909715</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.046499</td>\n",
       "      <td>0.078951</td>\n",
       "      <td>0.931796</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.029761</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.946025</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.022931</td>\n",
       "      <td>0.053083</td>\n",
       "      <td>0.954367</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.962709</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>0.041922</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017560</td>\n",
       "      <td>0.038561</td>\n",
       "      <td>0.967125</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016948</td>\n",
       "      <td>0.035995</td>\n",
       "      <td>0.969087</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.016466</td>\n",
       "      <td>0.033962</td>\n",
       "      <td>0.970559</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.016062</td>\n",
       "      <td>0.032304</td>\n",
       "      <td>0.973013</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.015715</td>\n",
       "      <td>0.030922</td>\n",
       "      <td>0.974485</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.015415</td>\n",
       "      <td>0.029751</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.015154</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>0.976448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.027881</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0.027125</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.014544</td>\n",
       "      <td>0.026461</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.014381</td>\n",
       "      <td>0.025873</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloaders = DataLoaders(train_dl, valid_dl)\n",
    "\n",
    "learner = Learner(dataloaders, nn.Linear(28 * 28, 1), opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy)\n",
    "learner.fit(20, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3046699",
   "metadata": {},
   "source": [
    "We can now upgrade our model from a linear function to a simple neural network of two linear layers separated by a non-linearity.\n",
    "\n",
    "The composition of one or more linear functions results in another linear function, but we need the linear functions decoupled from each other to be able to model more complex patterns, hence the use of a non-linearity.\n",
    "\n",
    "The non-linearity in this case is the rectified linear unit which when given an input tensor X, outputs max(X, 0), meaning any values less than 0 are replaced by 0.\n",
    "\n",
    "The first layer outputs 20 activations. The second one takes the 20 inputs and produces one activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "686d29f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28 * 28, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5faaf0",
   "metadata": {},
   "source": [
    "Being a deeper network, we can use a lower learning rate and more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8436ff25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.299396</td>\n",
       "      <td>0.431438</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.143788</td>\n",
       "      <td>0.225527</td>\n",
       "      <td>0.807655</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.079544</td>\n",
       "      <td>0.113536</td>\n",
       "      <td>0.917076</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.052429</td>\n",
       "      <td>0.076705</td>\n",
       "      <td>0.943081</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.039879</td>\n",
       "      <td>0.059873</td>\n",
       "      <td>0.957311</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.033456</td>\n",
       "      <td>0.050416</td>\n",
       "      <td>0.963690</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029745</td>\n",
       "      <td>0.044461</td>\n",
       "      <td>0.966634</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027316</td>\n",
       "      <td>0.040392</td>\n",
       "      <td>0.968597</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025558</td>\n",
       "      <td>0.037424</td>\n",
       "      <td>0.969578</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024193</td>\n",
       "      <td>0.035155</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023087</td>\n",
       "      <td>0.033352</td>\n",
       "      <td>0.973503</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.022164</td>\n",
       "      <td>0.031877</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.021379</td>\n",
       "      <td>0.030638</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.020699</td>\n",
       "      <td>0.029578</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.020105</td>\n",
       "      <td>0.028655</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.019579</td>\n",
       "      <td>0.027843</td>\n",
       "      <td>0.976938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.019109</td>\n",
       "      <td>0.027121</td>\n",
       "      <td>0.977920</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.018687</td>\n",
       "      <td>0.026475</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.018303</td>\n",
       "      <td>0.025893</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.017953</td>\n",
       "      <td>0.025366</td>\n",
       "      <td>0.979882</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.017631</td>\n",
       "      <td>0.024886</td>\n",
       "      <td>0.979882</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.017334</td>\n",
       "      <td>0.024447</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.017059</td>\n",
       "      <td>0.024046</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.016802</td>\n",
       "      <td>0.023676</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.016563</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.016338</td>\n",
       "      <td>0.023019</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.016125</td>\n",
       "      <td>0.022726</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.015925</td>\n",
       "      <td>0.022455</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.015735</td>\n",
       "      <td>0.022204</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.015555</td>\n",
       "      <td>0.021970</td>\n",
       "      <td>0.983317</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.015383</td>\n",
       "      <td>0.021751</td>\n",
       "      <td>0.983808</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.015220</td>\n",
       "      <td>0.021546</td>\n",
       "      <td>0.983808</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.015064</td>\n",
       "      <td>0.021355</td>\n",
       "      <td>0.983317</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.021175</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.014772</td>\n",
       "      <td>0.021007</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.014635</td>\n",
       "      <td>0.020848</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.014503</td>\n",
       "      <td>0.020699</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.014376</td>\n",
       "      <td>0.020558</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.014254</td>\n",
       "      <td>0.020424</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.014136</td>\n",
       "      <td>0.020297</td>\n",
       "      <td>0.983317</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner = Learner(dataloaders, simple_net, opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy)\n",
    "learner.fit(40, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80848a96",
   "metadata": {},
   "source": [
    "At this point we have:\n",
    "- According to the universal approximation theorem, a function that can approximate any problem to any level of accuracy given the right parameters\n",
    "- A method of finding the correct parameters via stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb54231b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
